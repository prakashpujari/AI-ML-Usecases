# ğŸš— Car Price Prediction â€” Complete ML Pipeline

## Project Overview

A production-grade, end-to-end machine learning pipeline for car price prediction with enterprise-level orchestration, monitoring, and deployment capabilities.

### ğŸ¯ What This Project Does

This project demonstrates a complete ML workflow:
1. **Data Generation & Validation** - Synthetic car data with quality checks
2. **Model Training** - Scikit-learn regression models with hyperparameter tuning
3. **Experiment Tracking** - MLflow integration for versioning and metrics
4. **Workflow Orchestration** - Apache Airflow for automated daily training
5. **API Service** - FastAPI backend for real-time predictions
6. **Interactive Dashboard** - Streamlit UI with model explainability (SHAP)
7. **Database Integration** - PostgreSQL for evaluation metrics storage
8. **Multi-Environment Deployment** - DEV, SIT, UAT, PROD configurations

### ğŸ“š Key Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **ML Framework** | Scikit-learn | Model training & evaluation |
| **Experiment Tracking** | MLflow | Run versioning, artifact storage |
| **Orchestration** | Apache Airflow | Automated workflow scheduling |
| **API** | FastAPI | High-performance REST API |
| **UI** | Streamlit | Interactive data exploration |
| **Database** | PostgreSQL | Metrics & evaluation results |
| **Containerization** | Docker | Environment consistency |
| **Deployment** | Docker Compose, Kubernetes | Multi-environment support |

# ğŸš— Car Price Prediction â€” Complete ML Pipeline

## ğŸ“– Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [Prerequisites](#prerequisites)
4. [Quick Start Guide](#quick-start-guide)
5. [Detailed Setup Instructions](#detailed-setup-instructions)
6. [Running Each Component](#running-each-component)
7. [Automatic Retraining System](#automatic-retraining-system) ğŸ”„
8. [API Documentation](#api-documentation)
9. [Using Streamlit Dashboard](#using-streamlit-dashboard)
10. [Airflow Orchestration](#airflow-orchestration)
11. [MLflow Experiment Tracking](#mlflow-experiment-tracking)
12. [Database Operations](#database-operations)
13. [Troubleshooting](#troubleshooting)

---

## Project Overview

A production-grade, end-to-end machine learning pipeline for car price prediction with enterprise-level orchestration, monitoring, and deployment capabilities.

### ğŸ¯ What This Project Does

This project demonstrates a complete ML workflow:
1. **Data Generation & Validation** - Synthetic car data with quality checks
2. **Model Training** - Scikit-learn regression models with hyperparameter tuning
3. **Experiment Tracking** - MLflow integration for versioning and metrics
4. **Workflow Orchestration** - Apache Airflow for automated daily training
5. **API Service** - FastAPI backend for real-time predictions
6. **Interactive Dashboard** - Streamlit UI with model explainability (SHAP)
7. **Database Integration** - PostgreSQL for evaluation metrics storage
8. **ğŸ”„ Automatic Retraining** - Drift detection & automatic model retraining on degradation
9. **Model Monitoring** - Performance degradation tracking with automatic alerts
10. **Multi-Environment Deployment** - DEV, SIT, UAT, PROD configurations

### ğŸ“š Key Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **ML Framework** | Scikit-learn | Model training & evaluation |
| **Experiment Tracking** | MLflow | Run versioning, artifact storage |
| **Orchestration** | Apache Airflow | Automated workflow scheduling |
| **API** | FastAPI | High-performance REST API |
| **UI** | Streamlit | Interactive data exploration |
| **Database** | PostgreSQL | Metrics & evaluation results |
| **Drift Detection** | SciPy, Pandas | Data/concept drift monitoring |
| **Containerization** | Docker | Environment consistency |
| **Deployment** | Docker Compose, Kubernetes | Multi-environment support |

---

## Architecture

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACES                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  Streamlit UI          Airflow WebUI        MLflow UI            â”‚
â”‚  (localhost:8501)      (localhost:8080)     (localhost:5000)     â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚                                 â”‚              â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚                â”‚                â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ FastAPI â”‚      â”‚ Airflow  â”‚     â”‚  MLflow  â”‚
        â”‚  API    â”‚      â”‚ Schedulerâ”‚     â”‚ Tracking â”‚
        â”‚(8000)   â”‚      â”‚ (Airflow)â”‚     â”‚ (5000)   â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚                â”‚              â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚            â”‚            â”‚
            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
            â”‚  Model â”‚   â”‚  Data  â”‚  â”‚ Metrics â”‚
            â”‚ Storageâ”‚   â”‚ Storageâ”‚  â”‚Database â”‚
            â”‚(models/â”‚   â”‚(data/) â”‚  â”‚(5433)   â”‚
            â”‚)       â”‚   â”‚        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
1. DATA GENERATION (train.py)
   â”œâ”€ Generate synthetic car data
   â””â”€ Save to data/trainset/train.csv

2. DATA VALIDATION (validate_data task)
   â”œâ”€ Check data quality
   â”œâ”€ Validate schema
   â””â”€ Log to Airflow

3. MODEL TRAINING (train_model task)
   â”œâ”€ Split train/test
   â”œâ”€ Train Scikit-learn model
   â”œâ”€ Log metrics to MLflow
   â””â”€ Save model to models/trained/

4. MODEL EVALUATION (evaluate_model task)
   â”œâ”€ Calculate performance metrics
   â”œâ”€ Generate SHAP explanations
   â”œâ”€ Store results in PostgreSQL
   â””â”€ Log to MLflow

5. MODEL REGISTRATION (register_model task)
   â”œâ”€ Register best model
   â”œâ”€ Promote to staging
   â””â”€ Update metrics DB

6. MONITORING & DRIFT DETECTION (automatic_retraining_dag) ğŸ”„
   â”œâ”€ Detect data drift (Kolmogorov-Smirnov test)
   â”œâ”€ Detect concept drift (error analysis)
   â”œâ”€ Check performance degradation (RÂ², RMSE)
   â”œâ”€ Calculate severity & confidence
   â”œâ”€ Log events to PostgreSQL
   â””â”€ Trigger retraining if needed

7. AUTOMATIC RETRAINING (automatic_retraining_dag) ğŸ”„
   â”œâ”€ Prepare training data (merge reference + recent)
   â”œâ”€ Execute retraining subprocess
   â”œâ”€ Validate improvements
   â”œâ”€ Log metrics to database
   â””â”€ Update production model

8. API SERVING (FastAPI)
   â”œâ”€ Load model from storage
   â”œâ”€ Accept prediction requests
   â”œâ”€ Return predictions + confidence
   â””â”€ Log to database

9. UI VISUALIZATION (Streamlit)
   â”œâ”€ Display predictions
   â”œâ”€ Show SHAP explanations
   â”œâ”€ Plot historical metrics
   â””â”€ Interactive feature exploration
```

---

## Prerequisites

### System Requirements

- **OS**: Windows 10/11, macOS, or Linux
- **Python**: 3.9 or higher
- **Docker**: 20.10+ (for containerized setup)
- **RAM**: 4GB minimum, 8GB recommended
- **Disk Space**: 2GB for dependencies and data

### Software to Install

1. **Python 3.9+** - Download from [python.org](https://www.python.org)
2. **Docker Desktop** - Download from [docker.com](https://www.docker.com)
3. **Git** - Download from [git-scm.com](https://www.git-scm.com)
4. **PostgreSQL (optional for native setup)** - Download from [postgresql.org](https://www.postgresql.org)

### Verify Installation

```powershell
# Check Python
python --version
# Expected: Python 3.9+

# Check Docker
docker --version
# Expected: Docker version 20.10+

# Check Git
git --version
# Expected: git version 2.x
```

---

## Quick Start Guide

### ğŸš€ Fastest Way to Get Running (Docker - Recommended)

```powershell
# 1. Clone the repository
git clone <repository-url>
cd ml_car_price_predection

# 2. Start all services with Docker Compose
docker-compose -f deployment/dev/docker-compose.dev.yml up -d

# 3. Wait for services to be healthy (30-60 seconds)
docker-compose -f deployment/dev/docker-compose.dev.yml ps

# 4. Access the services
- Streamlit UI:        http://localhost:8501
- FastAPI:             http://localhost:8000
- FastAPI Docs:        http://localhost:8000/docs
- MLflow:              http://localhost:5000
- PostgreSQL:          localhost:5433
```

**Expected Output:**
```
NAME           IMAGE                COMMAND              STATUS
car-api-dev    dev-api              "uvicorn..."         Up 30 seconds
car-ui-dev     dev-ui               "streamlit..."       Up 25 seconds
mlflow-dev     python:3.11-slim     "sh -c..."           Up 60+ seconds
postgres-dev   postgres:15-alpine   "docker-entry..."    Up 60+ seconds (healthy)
```

### ğŸ“± Services URLs After Startup

| Service | URL | Credentials |
|---------|-----|-------------|
| **Streamlit Dashboard** | http://localhost:8501 | None required |
| **FastAPI Docs** | http://localhost:8000/docs | Try it out button |
| **MLflow** | http://localhost:5000 | None required |
| **Database** | postgresql://postgres:postgres@localhost:5433/postgres | psql client |

---

## Detailed Setup Instructions

### Option A: Docker Setup (Recommended for Beginners)

#### Step 1: Clone Repository

```powershell
# On Windows PowerShell
git clone <repository-url>
cd ml_car_price_predection
```

#### Step 2: Verify Docker Installation

```powershell
docker --version
docker ps  # Should show running containers (if any)
```

#### Step 3: Start Development Stack

```powershell
# Start PostgreSQL, MLflow, FastAPI, and Streamlit
docker-compose -f deployment/dev/docker-compose.dev.yml up -d

# Monitor the startup process
docker-compose -f deployment/dev/docker-compose.dev.yml logs -f

# Wait for all services to become healthy (2-3 minutes)
```

**Screenshot Description of Expected Output:**

```
âœ” Network dev_ml-network  Created
âœ” Container postgres-dev  Started (healthy)
âœ” Container mlflow-dev    Started
âœ” Container car-api-dev   Started
âœ” Container car-ui-dev    Started
```

#### Step 4: Verify All Services Are Running

```powershell
docker-compose -f deployment/dev/docker-compose.dev.yml ps
```

**Expected Output Table:**
```
NAME           IMAGE                 STATUS                PORTS
postgres-dev   postgres:15-alpine    Up 2 minutes (healthy) 0.0.0.0:5433â†’5432
mlflow-dev     python:3.11-slim      Up 2 minutes          0.0.0.0:5000â†’5000
car-api-dev    dev-api               Up 2 minutes          0.0.0.0:8000â†’8000
car-ui-dev     dev-ui                Up 2 minutes          0.0.0.0:8501â†’8501
```

### Option B: Native Python Setup (For Development)

#### Step 1: Clone and Navigate

```powershell
git clone <repository-url>
cd ml_car_price_predection
```

#### Step 2: Create Virtual Environment

```powershell
# Create virtual environment
python -m venv .venv

# Activate it
.\.venv\Scripts\Activate.ps1

# If you get an execution policy error:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

#### Step 3: Install Dependencies

```powershell
# Upgrade pip, wheel, setuptools
python -m pip install --upgrade pip wheel setuptools

# Install project dependencies
pip install -r requirements.txt
```

**Expected Output:**
```
Successfully installed numpy-1.24.3 scikit-learn-1.3.0 fastapi-0.100.0 ...
```

#### Step 4: Start Services Individually

**Terminal 1 - FastAPI**:
```powershell
python -m uvicorn predict_api:app --host 0.0.0.0 --port 8000 --reload
```

**Expected Output:**
```
INFO:     Started server process [12345]
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Application startup complete
```

**Terminal 2 - Streamlit**:
```powershell
streamlit run streamlit_app.py
```

**Expected Output:**
```
  You can now view your Streamlit app in your browser.
  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

### Option C: Airflow Setup (For Orchestration)

#### Step 1: Verify Astro CLI Installation

```powershell
astro version
```

If not installed:
```powershell
# Install Astronomer CLI
winget install Astronomer.astro
# or download from https://www.astronomer.io/docs/astro/cli/install-cli
```

#### Step 2: Start Airflow

```powershell
astro dev start

# Wait for startup (2-3 minutes)
# You'll see: âœ” Project is running
```

**Expected Output:**
```
âœ” Project image has been updated
âœ” Project is running
âœ” Webserver: http://localhost:8080
âœ” Postgres: localhost:5432
âœ” Triggered Airflow Config to Restart
```

#### Step 3: Access Airflow UI

```
URL: http://localhost:8080
Username: admin
Password: admin
```

#### Step 4: Trigger Training DAG

In Airflow UI:
1. Navigate to DAGs
2. Find `train_model_dag`
3. Click the Play button (â–¶ï¸) to trigger
4. Click on the DAG to view execution

---

## Running Each Component

### 1. ğŸ¤– Model Training

#### Option A: Direct Python

```powershell
# Train model with 5000 synthetic samples
python train.py --n-samples 5000

# Train with custom parameters
python train.py --n-samples 10000 --test-size 0.2 --random-state 42
```

**Expected Output:**
```
INFO:root:Generating synthetic car price data...
INFO:root:Created 5000 samples with 11 features
INFO:root:Starting MLflow run...
INFO:root:Training Random Forest model...
INFO:root:Model training completed
INFO:root:RÂ² Score: 0.8765
INFO:root:RMSE: $4,321.45
INFO:root:Model saved to models/trained/model.pkl
```

#### Option B: Via Airflow DAG

```powershell
# Trigger via Airflow CLI
astro dev run dags trigger train_model_dag

# Or via Python API
python -m airflow dags trigger train_model_dag
```

**Airflow UI Screenshot Description:**

The DAG Graph View shows:
```
[validate_data] â†’ [train_model] â†’ [evaluate_model] â†’ [register_model]
                      â†“
                  [Log Metrics]
```

### 2. ğŸ”® Make Predictions

#### Using FastAPI Directly

```powershell
# Start API server
python -m uvicorn predict_api:app --host 0.0.0.0 --port 8000 --reload
```

#### Using Streamlit UI

1. Open http://localhost:8501
2. Select car features:
   - **Age**: Slider (0-20 years)
   - **Mileage**: Slider (0-200,000 km)
   - **Engine Size**: Slider (1.0-5.0 L)
   - **Brand**: Dropdown selector
3. Click "ğŸ”® Predict Price"
4. View results with confidence interval

**Streamlit UI Screenshot Description:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš— Car Price Prediction Dashboard      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ ğŸ“Š Feature Selection                    â”‚
â”‚ â”œâ”€ Age: [====â—â”€â”€â”€â”€] 5 years             â”‚
â”‚ â”œâ”€ Mileage: [â•â•â•â—â•â•â•â•â•] 75,000 km      â”‚
â”‚ â”œâ”€ Engine: [â•â•â—â•â•] 2.0L                 â”‚
â”‚ â””â”€ Brand: [Toyota â–¼]                    â”‚
â”‚                                         â”‚
â”‚ [ğŸ”® Predict Price Button]               â”‚
â”‚                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ’° PREDICTION RESULT                    â”‚
â”‚                                         â”‚
â”‚ Estimated Price: $18,500                â”‚
â”‚ Confidence: 85% (Â±$1,200)               â”‚
â”‚                                         â”‚
â”‚ ğŸ“ˆ Feature Importance (SHAP)            â”‚
â”‚ â”œâ”€ Mileage: â”â”â”â”â”â”â”â”â” (â†“ Price)         â”‚
â”‚ â”œâ”€ Age: â”â”â”â”â”â” (â†“ Price)                â”‚
â”‚ â””â”€ Engine: â”â” (â†‘ Price)                 â”‚
â”‚                                         â”‚
â”‚ ğŸ“Š Model Metrics                        â”‚
â”‚ â”œâ”€ RÂ² Score: 0.876                      â”‚
â”‚ â”œâ”€ RMSE: $4,321                         â”‚
â”‚ â””â”€ Latest Run: 2026-01-05 21:30         â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. ğŸ“Š MLflow Experiment Tracking

#### Access MLflow UI

```
URL: http://localhost:5000
```

**MLflow UI Screenshot Description:**

```
Experiments List View:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Experiment: car_price_prediction        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Runs:                                   â”‚
â”‚ â”œâ”€ Run ID: abc123def456                 â”‚
â”‚ â”‚  â”œâ”€ Status: FINISHED                  â”‚
â”‚ â”‚  â”œâ”€ Model: Random Forest              â”‚
â”‚ â”‚  â”œâ”€ RÂ² Score: 0.876                   â”‚
â”‚ â”‚  â”œâ”€ RMSE: 4321.45                     â”‚
â”‚ â”‚  â””â”€ Timestamp: 2026-01-05 21:30:45    â”‚
â”‚ â”‚                                       â”‚
â”‚ â””â”€ Run ID: xyz789uvw012                 â”‚
â”‚    â”œâ”€ Status: FINISHED                  â”‚
â”‚    â”œâ”€ Model: Gradient Boosting          â”‚
â”‚    â”œâ”€ RÂ² Score: 0.891                   â”‚
â”‚    â”œâ”€ RMSE: 3987.23                     â”‚
â”‚    â””â”€ Timestamp: 2026-01-05 20:15:30    â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Compare Model Runs

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Get best run
best_run = client.search_runs(
    experiment_names=["car_price_prediction"],
    filter_string="metrics.r2_score > 0.85",
    order_by=["metrics.r2_score DESC"],
    max_results=1
)[0]

print(f"Best Model RÂ² Score: {best_run.data.metrics['r2_score']}")
print(f"Artifacts: {best_run.data.tags}")
```

---

## API Documentation

### FastAPI Endpoints

#### 1. Health Check

**Request:**
```http
GET /health HTTP/1.1
Host: localhost:8000
```

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2026-01-05T21:35:00Z",
  "version": "1.0.0"
}
```

**Code Example:**
```python
import requests

response = requests.get("http://localhost:8000/health")
print(response.json())
# Output: {'status': 'healthy', ...}
```

#### 2. Model Information

**Request:**
```http
GET /info HTTP/1.1
Host: localhost:8000
```

**Response:**
```json
{
  "model_name": "car_price_predictor",
  "model_version": "1.0",
  "input_features": [
    "age", "mileage", "engine_size", 
    "brand", "fuel_type", "transmission",
    "color", "accident_history", "service_history",
    "ownership_history", "current_price"
  ],
  "output": "predicted_price",
  "accuracy_metrics": {
    "r2_score": 0.876,
    "rmse": 4321.45,
    "mae": 3456.78
  }
}
```

#### 3. Make Prediction

**Request:**
```http
POST /predict HTTP/1.1
Host: localhost:8000
Content-Type: application/json

{
  "age": 5,
  "mileage": 75000,
  "engine_size": 2.0,
  "brand": "Toyota",
  "fuel_type": "Petrol",
  "transmission": "Automatic",
  "color": "White",
  "accident_history": false,
  "service_history": true,
  "ownership_history": 1,
  "current_price": 15000
}
```

**Response:**
```json
{
  "predicted_price": 18500.50,
  "confidence_interval": {
    "lower": 17300.25,
    "upper": 19700.75
  },
  "confidence_level": 0.85,
  "feature_importance": {
    "mileage": 0.32,
    "age": 0.28,
    "engine_size": 0.18,
    "brand": 0.15,
    "fuel_type": 0.07
  },
  "model_version": "1.0",
  "timestamp": "2026-01-05T21:35:12Z"
}
```

**Code Examples:**

Python:
```python
import requests

payload = {
    "age": 5,
    "mileage": 75000,
    "engine_size": 2.0,
    "brand": "Toyota",
    "fuel_type": "Petrol",
    "transmission": "Automatic",
    "color": "White",
    "accident_history": False,
    "service_history": True,
    "ownership_history": 1,
    "current_price": 15000
}

response = requests.post(
    "http://localhost:8000/predict",
    json=payload
)

result = response.json()
print(f"Predicted Price: ${result['predicted_price']:.2f}")
print(f"Confidence: {result['confidence_level']*100:.1f}%")
```

cURL:
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "age": 5,
    "mileage": 75000,
    "engine_size": 2.0,
    "brand": "Toyota",
    "fuel_type": "Petrol",
    "transmission": "Automatic",
    "color": "White",
    "accident_history": false,
    "service_history": true,
    "ownership_history": 1,
    "current_price": 15000
  }'
```

### Interactive API Documentation

**Swagger UI:**
```
http://localhost:8000/docs
```

**Screenshot Description:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Swagger UI - FastAPI Documentation        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ GET /health                                â”‚
â”‚ GET /info                                  â”‚
â”‚ POST /predict                              â”‚
â”‚                                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ POST /predict                        â”‚  â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚ â”‚                                      â”‚  â”‚
â”‚ â”‚ [Try it out] Button                  â”‚  â”‚
â”‚ â”‚                                      â”‚  â”‚
â”‚ â”‚ Request Body:                        â”‚  â”‚
â”‚ â”‚ {                                    â”‚  â”‚
â”‚ â”‚   "age": 0,                          â”‚  â”‚
â”‚ â”‚   "mileage": 0,                      â”‚  â”‚
â”‚ â”‚   ...                                â”‚  â”‚
â”‚ â”‚ }                                    â”‚  â”‚
â”‚ â”‚                                      â”‚  â”‚
â”‚ â”‚ [Execute] Button                     â”‚  â”‚
â”‚ â”‚                                      â”‚  â”‚
â”‚ â”‚ Response:                            â”‚  â”‚
â”‚ â”‚ {                                    â”‚  â”‚
â”‚ â”‚   "predicted_price": 18500.50,       â”‚  â”‚
â”‚ â”‚   "confidence_interval": {...}       â”‚  â”‚
â”‚ â”‚ }                                    â”‚  â”‚
â”‚ â”‚                                      â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Automatic Retraining System ğŸ”„

### Overview

The automatic retraining system continuously monitors model performance and data drift, automatically triggering retraining when degradation is detected. This ensures your production model stays accurate without manual intervention.

### Features

#### 1. **Multi-Method Drift Detection**

```python
from scripts.automatic_retraining import AutomaticRetrainingOrchestrator
import pandas as pd

# Load reference and recent data
ref_data = pd.read_csv("data/trainset/train.csv")
recent_data = pd.read_csv("data/recent_data.csv")

# Create orchestrator
orchestrator = AutomaticRetrainingOrchestrator()

# Check if retraining needed
trigger = orchestrator.should_retrain(
    reference_data=ref_data,
    recent_data=recent_data,
    recent_predictions=predictions,
    recent_actuals=actuals,
    current_metrics={'r2': 0.85, 'rmse': 0.35}
)

if trigger.triggered:
    print(f"Retraining needed: {trigger.reason}")
    print(f"Severity: {trigger.severity}")
    print(f"Confidence: {trigger.confidence}%")
```

**Detection Methods:**

| Method | Threshold | Description |
|--------|-----------|-------------|
| **Data Drift** | p < 0.05 | Kolmogorov-Smirnov test detects distribution shift in features |
| **Concept Drift** | > 15% increase | Compares prediction errors across time windows |
| **Performance Drop** | > 5% | Monitors RÂ² score, RMSE, and accuracy |
| **Outliers** | > 5% of data | Z-score based outlier detection (>3Ïƒ) |

#### 2. **Severity Classification**

Events are classified by severity to prioritize action:

```
ğŸŸ¢ LOW (< 10%)       â†’ Monitor, log event
ğŸŸ¡ MEDIUM (10-15%)   â†’ Investigate, plan retraining
ğŸŸ  HIGH (15-20%)     â†’ Schedule retraining
ğŸ”´ CRITICAL (> 20%)  â†’ Immediate retraining
```

#### 3. **Automatic Execution**

The system automatically executes retraining when triggered:

```python
from scripts.retraining_executor import RetrainingExecutor

executor = RetrainingExecutor()
result = executor.execute_full_retraining_pipeline(
    reference_data=ref_data,
    recent_data=recent_data
)

print(f"Retraining Status: {result['status']}")
print(f"New RÂ² Score: {result['new_r2']}")
print(f"Improvement: {result['improvement_r2_percent']}%")
```

#### 4. **Event Logging**

All retraining events are logged to PostgreSQL for audit and analysis:

```sql
-- View recent retraining events
SELECT triggered_at, trigger_type, severity, execution_successful
FROM model_retraining_events
ORDER BY triggered_at DESC
LIMIT 10;

-- Check improvement metrics
SELECT improvement_r2_percent, improvement_rmse_percent, improvement_accuracy_percent
FROM model_retraining_events
WHERE execution_successful = TRUE;
```

### Quick Start

#### 1. **Check if Retraining Needed**

```bash
python scripts/automatic_retraining.py \
  --reference-data data/trainset/train.csv \
  --recent-data data/recent_data.csv \
  --recent-predictions predictions.npy \
  --recent-actuals actuals.npy
```

#### 2. **Execute Retraining Pipeline**

```bash
python scripts/retraining_executor.py \
  --reference-data data/trainset/train.csv \
  --recent-data data/recent_data.csv
```

#### 3. **Schedule with Airflow**

The DAG `automatic_model_retraining` runs every 6 hours:

```bash
# View in Airflow UI
http://localhost:8080/dags/automatic_model_retraining
```

### Configuration

Edit thresholds in `scripts/automatic_retraining.py`:

```python
orchestrator = AutomaticRetrainingOrchestrator(
    data_drift_threshold=0.05,          # KS test p-value threshold
    performance_threshold=0.05,         # RÂ² drop threshold
    min_samples_for_retraining=100,    # Minimum recent samples
    concept_drift_window=100            # Error comparison window
)
```

### Monitoring

Check retraining history and metrics:

```python
import psycopg2

conn = psycopg2.connect(
    host="localhost",
    port=5433,
    database="postgres",
    user="postgres",
    password="postgres"
)

cursor = conn.cursor()

# Get latest event
cursor.execute("""
    SELECT triggered_at, trigger_type, severity, 
           improvement_r2_percent, execution_successful
    FROM model_retraining_events
    ORDER BY triggered_at DESC
    LIMIT 1
""")

event = cursor.fetchone()
print(f"Latest event: {event}")
cursor.close()
conn.close()
```

### Files

- **Detection Logic**: [scripts/automatic_retraining.py](scripts/automatic_retraining.py) (850 lines)
- **Execution**: [scripts/retraining_executor.py](scripts/retraining_executor.py) (600 lines)
- **Airflow DAG**: [airflow/dags/automatic_retraining_dag.py](airflow/dags/automatic_retraining_dag.py)
- **Full Guide**: [AUTOMATIC_RETRAINING_GUIDE.md](AUTOMATIC_RETRAINING_GUIDE.md)
- **Quick Reference**: [AUTOMATIC_RETRAINING_QUICK_REFERENCE.md](AUTOMATIC_RETRAINING_QUICK_REFERENCE.md)

---

## Using Streamlit Dashboard

### Access Dashboard

```
http://localhost:8501
```

### Features

#### 1. Single Prediction
1. Adjust sliders for car features
2. Select brand from dropdown
3. Click "ğŸ”® Predict Price"
4. View prediction with confidence interval

#### 2. Batch Predictions
1. Upload CSV file with car data
2. Click "ğŸ“¤ Process File"
3. Download results as CSV

#### 3. Model Comparison
1. Select two different model runs from dropdown
2. View side-by-side metrics comparison
3. Compare feature importance plots

#### 4. SHAP Explainability
1. Make a prediction
2. Scroll to "ğŸ” Model Explanation"
3. View SHAP force plot showing feature impacts
4. Red = increases price, Blue = decreases price

#### 5. Historical Performance
1. View "ğŸ“ˆ Training History" tab
2. See model metrics over time
3. Track RÂ² Score, RMSE, MAE trends
4. Compare different model versions

**Streamlit Dashboard Screenshot Description:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸš— Car Price Prediction Dashboard        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚ [ğŸ”® Prediction] [ğŸ“ˆ Trends] [ğŸ“Š Metrics]â”‚
â”‚                                          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                          â”‚
â”‚ ğŸ“Š FEATURE SELECTION                    â”‚
â”‚                                          â”‚
â”‚ Age (years):                            â”‚
â”‚ [0] â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€ [20]                   â”‚
â”‚ Current: 5 years                        â”‚
â”‚                                          â”‚
â”‚ Mileage (km):                           â”‚
â”‚ [0] â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€ [200,000]              â”‚
â”‚ Current: 75,000 km                      â”‚
â”‚                                          â”‚
â”‚ Engine Size (L):                        â”‚
â”‚ [1.0] â”€â”€â—â”€â”€â”€ [5.0]                     â”‚
â”‚ Current: 2.0 L                          â”‚
â”‚                                          â”‚
â”‚ Brand:                                  â”‚
â”‚ [Toyota â–¼]                              â”‚
â”‚                                          â”‚
â”‚ Fuel Type:                              â”‚
â”‚ [Petrol â–¼]                              â”‚
â”‚                                          â”‚
â”‚ [ğŸ”® Predict Price]                      â”‚
â”‚                                          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                          â”‚
â”‚ ğŸ’° PREDICTION RESULT                    â”‚
â”‚                                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Estimated Price                      â”‚â”‚
â”‚ â”‚                                      â”‚â”‚
â”‚ â”‚           ğŸ’µ $18,500                 â”‚â”‚
â”‚ â”‚                                      â”‚â”‚
â”‚ â”‚ Confidence Range: $17,300 - $19,700  â”‚â”‚
â”‚ â”‚ Confidence Level: 85% â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘     â”‚â”‚
â”‚ â”‚                                      â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                          â”‚
â”‚ ğŸ” MODEL EXPLANATION (SHAP)             â”‚
â”‚                                          â”‚
â”‚ Feature Impact on Price:                â”‚
â”‚ (Red = increases, Blue = decreases)     â”‚
â”‚                                          â”‚
â”‚ Mileage: â”â”â”â”â”â”â”â”â” (â†“ $3,200)           â”‚
â”‚ Age: â”â”â”â”â”â” (â†“ $2,100)                 â”‚
â”‚ Engine: â”â” (â†‘ $1,500)                  â”‚
â”‚ Brand: â” (â†‘ $800)                      â”‚
â”‚                                          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                          â”‚
â”‚ ğŸ“ˆ MODEL METRICS                        â”‚
â”‚                                          â”‚
â”‚ RÂ² Score:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 0.876              â”‚
â”‚ RMSE:      $4,321                       â”‚
â”‚ MAE:       $3,457                       â”‚
â”‚ Training Samples: 5,000                 â”‚
â”‚                                          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                          â”‚
â”‚ âœ… Model Performance: Excellent         â”‚
â”‚    (>0.85 RÂ² score)                     â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Airflow Orchestration

### Accessing Airflow

```
URL: http://localhost:8080
Username: admin
Password: admin
```

### DAG: train_model_dag

#### DAG Graph

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  START DATE â”‚
                    â”‚2026-01-01   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚ validate_   â”‚
                    â”‚ data        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   train_    â”‚
                    â”‚   model     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚ evaluate_   â”‚
                    â”‚ model       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  register_  â”‚
                    â”‚  model      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   monitor_  â”‚
                    â”‚   performance
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Task Descriptions

| Task | Purpose | Duration | Status |
|------|---------|----------|--------|
| **validate_data** | Check data quality, schema, completeness | ~10s | âœ… |
| **train_model** | Train ML model with hyperparameter tuning | ~2-5m | âœ… |
| **evaluate_model** | Calculate metrics, generate SHAP plots | ~1-2m | âœ… |
| **register_model** | Register in MLflow, update metadata | ~30s | âœ… |
| **monitor_performance** | Log to database, create alerts | ~20s | âœ… |

### Triggering DAG Manually

#### Via Airflow UI

1. Navigate to `http://localhost:8080/home`
2. Find `train_model_dag` in the DAG list
3. Click the â–¶ï¸ **Play** button
4. Click on the DAG name to view execution

**Expected Screenshots:**

Graph View:
```
Shows execution progress with green checkmarks
for completed tasks, blue for running, red for failed
```

Log Output:
```
[2026-01-05 21:45:30] INFO - Starting DAG: train_model_dag
[2026-01-05 21:45:31] INFO - Task: validate_data started
[2026-01-05 21:45:35] INFO - Validated 5000 records
[2026-01-05 21:45:36] INFO - Task: validate_data completed âœ“
[2026-01-05 21:45:37] INFO - Task: train_model started
...
```

#### Via Command Line

```powershell
# Trigger DAG
astro dev run dags trigger train_model_dag

# View execution logs
astro dev logs --scheduler
```

### Scheduling

The DAG is scheduled to run **daily at 2:00 AM** by default:

```python
default_args = {
    'start_date': datetime(2026, 1, 1),
    'schedule_interval': '0 2 * * *',  # Daily at 2 AM
}
```

To modify schedule, edit [dags/train_dag.py](dags/train_dag.py).

---

## MLflow Experiment Tracking

### Access MLflow

```
http://localhost:5000
```

### Logging Metrics from Code

```python
import mlflow

# Start experiment
mlflow.set_experiment("car_price_prediction")

with mlflow.start_run(run_name="my_model_v1"):
    # Log parameters
    mlflow.log_param("model_type", "Random Forest")
    mlflow.log_param("n_estimators", 100)
    
    # Log metrics
    mlflow.log_metric("r2_score", 0.876)
    mlflow.log_metric("rmse", 4321.45)
    
    # Log model
    mlflow.sklearn.log_model(model, "model")
    
    # Log artifacts
    mlflow.log_artifact("feature_importance.png")

print("Run logged successfully!")
```

### Querying Runs Programmatically

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Get experiment
exp = client.get_experiment_by_name("car_price_prediction")

# List all runs
runs = client.search_runs(experiment_ids=[exp.experiment_id])

for run in runs:
    print(f"Run ID: {run.info.run_id}")
    print(f"RÂ² Score: {run.data.metrics.get('r2_score', 'N/A')}")
    print(f"RMSE: {run.data.metrics.get('rmse', 'N/A')}")
    print("---")
```

---

## Database Operations

### PostgreSQL Connection Details

```
Host: localhost
Port: 5433
Database: postgres
Username: postgres
Password: postgres
```

### Query Results Using Python

```powershell
# List all training runs
python query_results.py runs

# Show metrics for specific run
python query_results.py metrics 1

# Show trend (last 5 runs)
python query_results.py trend 5

# Compare two runs
python query_results.py compare 1 2
```

**Expected Output:**

```
Run ID: 1
â”œâ”€ Timestamp: 2026-01-05 21:30:45
â”œâ”€ Model: Random Forest
â”œâ”€ RÂ² Score: 0.876
â”œâ”€ RMSE: 4321.45
â””â”€ Status: COMPLETED

Run ID: 2
â”œâ”€ Timestamp: 2026-01-05 20:15:30
â”œâ”€ Model: Gradient Boosting
â”œâ”€ RÂ² Score: 0.891
â”œâ”€ RMSE: 3987.23
â””â”€ Status: COMPLETED
```

### Direct Database Access

```python
import psycopg2

conn = psycopg2.connect(
    host="localhost",
    port=5433,
    database="postgres",
    user="postgres",
    password="postgres"
)

cursor = conn.cursor()
cursor.execute("""
    SELECT run_id, model_name, r2_score, rmse 
    FROM model_runs 
    ORDER BY created_at DESC 
    LIMIT 10
""")

for row in cursor.fetchall():
    print(f"Run: {row[0]}, Model: {row[1]}, RÂ²: {row[2]}, RMSE: {row[3]}")

cursor.close()
conn.close()
```

---

## Troubleshooting

### Issue 1: Services Won't Start

**Problem:**
```
Error: error building, (re)creating or starting project containers
Error response from daemon: Bind for 0.0.0.0:5432 failed: port is already allocated
```

**Solution:**
```powershell
# Check what's using the port
netstat -ano | findstr :5432

# Kill the process (replace PID with actual process ID)
taskkill /PID <PID> /F

# Or use different port in docker-compose.dev.yml
# Change: "5434:5432" instead of "5433:5432"
```

### Issue 2: FastAPI Connection Refused

**Problem:**
```
ConnectionRefusedError: Failed to establish a new connection
```

**Solution:**
```powershell
# Verify API is running
docker-compose -f deployment/dev/docker-compose.dev.yml ps | findstr api

# If not running, restart it
docker-compose -f deployment/dev/docker-compose.dev.yml restart car-api-dev

# Check logs
docker-compose -f deployment/dev/docker-compose.dev.yml logs car-api-dev
```

### Issue 3: Streamlit Can't Connect to API

**Problem:**
```
streamlit_app.py: Unable to connect to API at http://localhost:8000
```

**Solution:**
1. Ensure API is running on port 8000
2. Modify [streamlit_app.py](streamlit_app.py) line with API URL:
```python
API_URL = "http://host.docker.internal:8000"  # For Docker-based Streamlit
# or
API_URL = "http://localhost:8000"  # For native Streamlit
```

### Issue 4: Database Connection Timeout

**Problem:**
```
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed
```

**Solution:**
```powershell
# Ensure PostgreSQL is running and healthy
docker-compose -f deployment/dev/docker-compose.dev.yml ps | findstr postgres-dev

# If unhealthy, restart it
docker-compose -f deployment/dev/docker-compose.dev.yml restart postgres-dev

# Wait 10-15 seconds for health check to pass
Start-Sleep -Seconds 15
docker-compose -f deployment/dev/docker-compose.dev.yml ps
```

### Issue 5: SHAP Installation Fails (Windows)

**Problem:**
```
error: Microsoft Visual C++ 14.0 or greater is required
```

**Solution:**
```powershell
# Install from pre-built wheel
pip install --only-binary :all: shap

# Or use Conda (recommended)
conda install -c conda-forge shap
```

### Issue 6: Airflow DAG Not Appearing

**Problem:**
```
No DAGs appear in Airflow UI
```

**Solution:**
```powershell
# Ensure airflow_settings.yaml is correct
cat airflow_settings.yaml

# Restart Airflow
astro dev stop
astro dev start

# Check DAG parsing
astro dev run dags list
```

---

## Project Structure

```
ml_car_price_predection/
â”œâ”€â”€ src/                           # Main source code
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_generator.py     # Generate synthetic data
â”‚   â”‚   â”œâ”€â”€ ingestion.py          # Data loading
â”‚   â”‚   â”œâ”€â”€ preprocessing.py      # Feature engineering
â”‚   â”‚   â”œâ”€â”€ split_data.py         # Train/test split
â”‚   â”‚   â””â”€â”€ validation.py         # Data quality checks
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model.py              # Model architecture
â”‚   â”‚   â”œâ”€â”€ train.py              # Training logic
â”‚   â”‚   â”œâ”€â”€ evaluate.py           # Evaluation metrics
â”‚   â”‚   â””â”€â”€ predict.py            # Inference code
â”‚   â””â”€â”€ pipelines/
â”‚       â”œâ”€â”€ training_pipeline.py  # Full training flow
â”‚       â”œâ”€â”€ inference_pipeline.py # Prediction pipeline
â”‚       â””â”€â”€ monitoring_pipeline.py# Performance monitoring
â”‚
â”œâ”€â”€ dags/                          # Airflow DAGs
â”‚   â”œâ”€â”€ train_dag.py              # Training orchestration
â”‚   â””â”€â”€ automatic_retraining_dag.py # ğŸ”„ Automatic retraining scheduler
â”‚
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ db_utils.py               # Database utilities
â”‚   â”œâ”€â”€ data_validation.py        # Data checks
â”‚   â”œâ”€â”€ monitor.py                # Performance monitoring
â”‚   â”œâ”€â”€ query_results.py          # Query evaluation metrics
â”‚   â”œâ”€â”€ automatic_retraining.py   # ğŸ”„ Drift detection engine (850 lines)
â”‚   â””â”€â”€ retraining_executor.py    # ğŸ”„ Retraining execution (600 lines)
â”‚
â”œâ”€â”€ models/                        # Model storage
â”‚   â”œâ”€â”€ trained/                  # Trained model files
â”‚   â”œâ”€â”€ staging/                  # Staging models
â”‚   â””â”€â”€ production/               # Production models
â”‚
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ trainset/                 # Training data
â”‚   â””â”€â”€ testset/                  # Test data
â”‚
â”œâ”€â”€ deployment/                    # Environment configs
â”‚   â”œâ”€â”€ dev/                      # Development setup
â”‚   â”œâ”€â”€ sit/                      # System integration test
â”‚   â”œâ”€â”€ uat/                      # User acceptance test
â”‚   â””â”€â”€ prod/                     # Production setup
â”‚
â”œâ”€â”€ k8s/                          # Kubernetes manifests
â”‚   â”œâ”€â”€ deployment-api.yaml
â”‚   â”œâ”€â”€ deployment-ui.yaml
â”‚   â”œâ”€â”€ service-api.yaml
â”‚   â””â”€â”€ service-ui.yaml
â”‚
â”œâ”€â”€ predict_api.py                # FastAPI app
â”œâ”€â”€ streamlit_app.py              # Streamlit UI
â”œâ”€â”€ train.py                       # Standalone training script
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ AUTOMATIC_RETRAINING_GUIDE.md # ğŸ”„ Comprehensive retraining guide (2,500+ lines)
â””â”€â”€ AUTOMATIC_RETRAINING_QUICK_REFERENCE.md # ğŸ”„ Quick reference & APIs
```

---

## Common Workflows

### Workflow 1: Train New Model and Deploy

```powershell
# 1. Start all services
docker-compose -f deployment/dev/docker-compose.dev.yml up -d

# 2. Train model
python train.py --n-samples 10000

# 3. Check metrics in MLflow
# Visit http://localhost:5000

# 4. Verify API
curl http://localhost:8000/health

# 5. Make prediction in Streamlit
# Visit http://localhost:8501
```

### Workflow 2: Schedule Daily Training

```powershell
# 1. Start Airflow
astro dev start

# 2. Access UI
# http://localhost:8080

# 3. Trigger DAG
# Click play button on train_model_dag

# 4. Monitor execution
# View logs and metrics in real-time
```

### Workflow 3: Compare Model Versions

```python
import mlflow

client = mlflow.tracking.MlflowClient()

# Get experiments
exp = client.get_experiment_by_name("car_price_prediction")

# Get top 2 runs by RÂ² score
runs = client.search_runs(
    experiment_ids=[exp.experiment_id],
    order_by=["metrics.r2_score DESC"],
    max_results=2
)

# Compare
for i, run in enumerate(runs):
    print(f"\nModel {i+1}:")
    print(f"  RÂ² Score: {run.data.metrics['r2_score']:.3f}")
    print(f"  RMSE: {run.data.metrics['rmse']:.2f}")
    print(f"  Created: {run.info.start_time}")
```

---

## Next Steps

1. **Customize with Your Data**: Replace synthetic data with real car listings
2. **Tune Hyperparameters**: Modify [src/models/train.py](src/models/train.py)
3. **Add Features**: Enhance feature engineering in [src/data/preprocessing.py](src/data/preprocessing.py)
4. **Configure Automatic Retraining**: ğŸ”„ Set thresholds in [scripts/automatic_retraining.py](scripts/automatic_retraining.py)
5. **Monitor Drift Events**: Check [AUTOMATIC_RETRAINING_GUIDE.md](AUTOMATIC_RETRAINING_GUIDE.md) for SQL queries
6. **Deploy to Cloud**: Use Kubernetes manifests in [k8s/](k8s/) for Kubernetes deployment
7. **Set Up Alerts**: Monitor model degradation in [scripts/monitor.py](scripts/monitor.py)

---

## What's New in This Version ğŸ”„

### Automatic Model Retraining System

This release introduces **automatic drift detection and model retraining** with:

- **3 Detection Methods**:
  - Data Drift (Kolmogorov-Smirnov test)
  - Concept Drift (error analysis)
  - Performance Degradation (RÂ², RMSE, accuracy)

- **Severity Classification**: LOW, MEDIUM, HIGH, CRITICAL
- **Confidence Scoring**: Each trigger includes confidence metrics
- **Automatic Execution**: Models retrain and update automatically
- **Event Logging**: Full audit trail in PostgreSQL
- **Airflow Integration**: Scheduled every 6 hours with task pipeline

### New Files

- [scripts/automatic_retraining.py](scripts/automatic_retraining.py) - Drift detection engine
- [scripts/retraining_executor.py](scripts/retraining_executor.py) - Execution pipeline
- [airflow/dags/automatic_retraining_dag.py](airflow/dags/automatic_retraining_dag.py) - Airflow scheduling
- [AUTOMATIC_RETRAINING_GUIDE.md](AUTOMATIC_RETRAINING_GUIDE.md) - Comprehensive documentation
- [AUTOMATIC_RETRAINING_QUICK_REFERENCE.md](AUTOMATIC_RETRAINING_QUICK_REFERENCE.md) - Quick reference

---

## Support & Documentation

- **Automatic Retraining**: [AUTOMATIC_RETRAINING_GUIDE.md](AUTOMATIC_RETRAINING_GUIDE.md) ğŸ”„
- **Quick Reference**: [AUTOMATIC_RETRAINING_QUICK_REFERENCE.md](AUTOMATIC_RETRAINING_QUICK_REFERENCE.md) ğŸ”„
- **MLflow Docs**: https://mlflow.org/docs/latest/
- **Airflow Docs**: https://airflow.apache.org/docs/
- **FastAPI Docs**: https://fastapi.tiangolo.com/
- **Streamlit Docs**: https://docs.streamlit.io/
- **PostgreSQL Docs**: https://www.postgresql.org/docs/

---

## License

This project is provided as-is for educational and development purposes.

---

**Last Updated**: January 6, 2026  
**Version**: 2.0 (with Automatic Retraining)

---

If you'd like, I can:

- add a Streamlit fallback to call the local `models/model.pkl` directly when the API is down (so the UI still predicts without the API),
- add `shap` to the model artifact `mlruns/.../artifacts/requirements.txt`, or
- attempt to reproduce and fix the `pip install` failure observed in your environment (paste the pip error output here and I'll diagnose).


2. Notes:
- The `mlflow` service runs the MLflow UI at `http://localhost:5000` and stores artifacts under `./mlruns`.
- The `train` service runs once and writes `models/model.pkl` to the shared `./models` folder (used by the API and UI).
- The `api` is available at `http://localhost:8000` (FastAPI) and the Streamlit UI at `http://localhost:8501`.

3. To re-run training, you can run only the `train` service:

```powershell
docker-compose run --rm train
```

